#!/bin/bash
set -e

# High-Iteration Benchmark Runner for Grainchain
# This script runs comprehensive benchmarks with configurable iterations (default: 50)
# Usage: ./scripts/benchmark_high_iteration.sh [iterations] [providers...]

ITERATIONS=${1:-50}
PROVIDERS=${2:-"local e2b"}
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
OUTPUT_DIR="benchmarks/results/high_iteration"
CONFIG_FILE="benchmarks/configs/high_iteration.json"

echo "🚀 Starting High-Iteration Grainchain Benchmarks"
echo "📊 Iterations: $ITERATIONS"
echo "🔧 Providers: $PROVIDERS"
echo "📁 Output: $OUTPUT_DIR"
echo "⏰ Started: $(date)"
echo "=================================================="

# Create output directory
mkdir -p "$OUTPUT_DIR"

# Update config with specified iterations
if command -v jq >/dev/null 2>&1; then
    echo "📝 Updating config with $ITERATIONS iterations..."
    jq ".iterations = $ITERATIONS" "$CONFIG_FILE" > "$CONFIG_FILE.tmp" && mv "$CONFIG_FILE.tmp" "$CONFIG_FILE"
else
    echo "⚠️  jq not found, using default config iterations"
fi

# Activate virtual environment
if [ -f ".venv/bin/activate" ]; then
    echo "🐍 Activating virtual environment..."
    source .venv/bin/activate
else
    echo "❌ Virtual environment not found. Please run 'uv venv && source .venv/bin/activate && uv sync --all-extras'"
    exit 1
fi

# Run benchmarks for each provider
for provider in $PROVIDERS; do
    echo ""
    echo "🧪 Testing provider: $provider"
    echo "⏱️  This may take several minutes with $ITERATIONS iterations..."

    # Run the benchmark
    if python benchmarks/scripts/grainchain_benchmark.py \
        --providers "$provider" \
        --config "$CONFIG_FILE" \
        --output "$OUTPUT_DIR"; then
        echo "✅ $provider benchmark completed successfully"
    else
        echo "❌ $provider benchmark failed"
        continue
    fi
done

# Generate comprehensive report
echo ""
echo "📊 Generating comprehensive analysis report..."
REPORT_FILE="$OUTPUT_DIR/comprehensive_report_${TIMESTAMP}.md"

cat > "$REPORT_FILE" << EOF
# High-Iteration Grainchain Benchmark Report

**Generated:** $(date)
**Iterations:** $ITERATIONS per scenario
**Providers:** $PROVIDERS
**Total Tests:** $(($(echo $PROVIDERS | wc -w) * 5 * ITERATIONS))

## Executive Summary

This report contains results from high-iteration benchmarking with $ITERATIONS iterations per test scenario.
The increased sample size provides more statistically significant results and better confidence intervals.

## Key Benefits of High-Iteration Testing

- **Statistical Significance**: With $ITERATIONS iterations, we can detect smaller performance differences
- **Confidence Intervals**: More reliable estimates of true performance characteristics
- **Outlier Detection**: Better identification of edge cases and performance anomalies
- **Trend Analysis**: Ability to detect performance patterns and consistency

## Results

EOF

# Add results from each provider
for provider in $PROVIDERS; do
    if [ -f "$OUTPUT_DIR/grainchain_benchmark_${provider}_${TIMESTAMP}.json" ]; then
        echo "### $provider Provider Results" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        echo "Detailed results available in: \`grainchain_benchmark_${provider}_${TIMESTAMP}.json\`" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
    fi
done

cat >> "$REPORT_FILE" << EOF

## Usage Notes

This high-iteration benchmark was run manually and is not part of the standard CI/CD pipeline.
To run your own high-iteration benchmark:

\`\`\`bash
# Run with custom iterations (e.g., 100)
./scripts/benchmark_high_iteration.sh 100

# Run specific providers with custom iterations
./scripts/benchmark_high_iteration.sh 25 "local e2b"

# Run all available providers
./scripts/benchmark_high_iteration.sh 50 "local e2b daytona morph"
\`\`\`

## Statistical Analysis

With $ITERATIONS iterations per scenario, these results provide:
- 95% confidence intervals for performance metrics
- Detection of performance variations < 5%
- Reliable outlier identification
- Trend analysis capabilities

---
*Generated by Grainchain High-Iteration Benchmark Suite*
EOF

echo ""
echo "🎉 High-iteration benchmarking completed!"
echo "📊 Results saved to: $OUTPUT_DIR"
echo "📋 Report available: $REPORT_FILE"
echo "⏰ Completed: $(date)"
echo ""
echo "🔍 To view results:"
echo "   cat $REPORT_FILE"
echo ""
echo "📈 For detailed analysis:"
echo "   ls $OUTPUT_DIR/"
